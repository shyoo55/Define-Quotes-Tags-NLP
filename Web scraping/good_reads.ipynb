{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem, SoftwareEngine, HardwareType, SoftwareType, Popularity\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url,parser):\n",
    "    \"\"\"\n",
    "    Download the html via request library,\n",
    "    Useing User Agent to avoid anti-scraer detiction \n",
    "    Using beautifulsoup to parse content\n",
    "    \n",
    "    Arguments\n",
    "    url for the target site \n",
    "    parser to be used to parse data('lxml','html','html5lib')\n",
    "    \n",
    "    return soup of html content\n",
    "    \n",
    "    \"\"\"\n",
    "    software_names = [SoftwareName.CHROME.value]\n",
    "    operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]   \n",
    "\n",
    "    user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=10000)\n",
    "\n",
    "        # Get list of user agents.\n",
    "    user_agents = user_agent_rotator.get_user_agents()\n",
    "\n",
    "        # Get Random User Agent String.\n",
    "    user_agent = user_agent_rotator.get_random_user_agent()\n",
    "    headers = {'User-agent':user_agent}\n",
    "    if not os.path.exists('response'):\n",
    "        os.makedirs('response')\n",
    "    r = req.get(url, headers = headers)\n",
    "    with open ('response/response',mode = 'w', encoding = 'UTF-8') as file:\n",
    "        file.write(r.text)\n",
    "    with open ('response/response',mode = 'r', encoding = 'UTF-8') as file:\n",
    "        soup = bs(file,parser)\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(url):\n",
    "    soup = get_soup(url,'lxml')\n",
    "    category_list = soup.findAll('li', class_=\"greyText\")\n",
    "    cat_dic = {}\n",
    "    for i in range(len(category_list)):\n",
    "        category = category_list[i].text.split()[0]\n",
    "        link = category_list[i].a['href']\n",
    "        cat_dic[category] = main_link+link\n",
    "    return cat_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(soup):\n",
    "    quote_list = soup.findAll('div', attrs={'class':'quote'})\n",
    "    d={}\n",
    "    for q in quote_list:\n",
    "        try:\n",
    "            author = q.find('div',  attrs={'class':'quoteDetails'}).span.text.split('\\n')[1].strip()\n",
    "            text = q.find('div',  attrs={'class':'quoteDetails'}).find('div',  attrs={'class':'quoteText'}).text.split('\\n')[1].strip().replace('”','').replace('“','')\n",
    "        except:\n",
    "            continue\n",
    "        if author and text:\n",
    "            d ['quot'] = text\n",
    "            d ['author'] = author\n",
    "            d['category'] = category\n",
    "\n",
    "        with open(\"data.txt\", \"a\") as outfile:\n",
    "            json.dump(d, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(file_name):\n",
    "    df_list = []\n",
    "    with open (file_name,\"r\") as j_file:\n",
    "        for l in j_file:\n",
    "            dic = {}\n",
    "            data=json.loads(l)\n",
    "            try:\n",
    "                dic['quot'] = data['quot']\n",
    "                dic['author'] = data['author']\n",
    "                dic['category'] = data['category']\n",
    "                df_list.append(dic)\n",
    "            except:\n",
    "                continue\n",
    "    df = pd.DataFrame(df_list,columns = ['quot','author','category'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_link = 'https://www.goodreads.com'\n",
    "url = main_link + '/quotes'\n",
    "categories = get_categories(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_categories = []\n",
    "scraped_page = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Love\n",
      "[****************************************************************************************************] 100%\n",
      " Life\n",
      "[****************************************************************************************************] 100%\n",
      " Inspirational\n",
      "[****************************************************************************************************] 100%\n",
      " Humor\n",
      "[****************************************************************************************************] 100%\n",
      " Philosophy\n",
      "[****************************************************************************************************] 100%\n",
      " God\n",
      "[****************************************************************************************************] 100%\n",
      " Truth\n",
      "[****************************************************************************************************] 100%\n",
      " Wisdom\n",
      "[****************************************************************************************************] 100%\n",
      " Poetry\n",
      "[****************************************************************************************************] 100%\n",
      " Romance\n",
      "[****************************************************************************************************] 100%\n",
      " Death\n",
      "[****************************************************************************************************] 100%\n",
      " Happiness\n",
      "[****************************************************************************************************] 100%\n",
      " Hope\n",
      "[****************************************************************************************************] 100%\n",
      " Faith\n",
      "[****************************************************************************************************] 100%\n",
      " Inspiration\n",
      "[****************************************************************************************************] 100%\n",
      " Quotes\n",
      "[****************************************************************************************************] 100%\n",
      " Writing\n",
      "[****************************************************************************************************] 100%\n",
      " Religion\n",
      "[****************************************************************************************************] 100%\n",
      " Motivational\n",
      "[****************************************************************************************************] 100%\n",
      " Relationships\n",
      "[****************************************************************************************************] 100%\n",
      " Success\n",
      "[****************************************************************************************************] 100%\n",
      " Spirituality\n",
      "[****************************************************************************************************] 100%\n",
      " Time\n",
      "[****************************************************************************************************] 100%\n",
      " Knowledge\n",
      "[****************************************************************************************************] 100%\n",
      " Science\n",
      "[****************************************************************************************************] 100%\n",
      " Motivation\n",
      "[****************************************************************************************************] 100%"
     ]
    }
   ],
   "source": [
    "for k ,v in categories.items():\n",
    "    if k in scraped_categories:\n",
    "        print('\\n',k)\n",
    "        for i in range(101):\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(\"[%-10s] %d%%\" % ('*'*i, 1*i))\n",
    "            sys.stdout.flush()\n",
    "        continue\n",
    "        \n",
    "    url = v + '?page='\n",
    "    category = k\n",
    "    print('\\n', k)\n",
    "    \n",
    "    for i in range(1,101):\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"[%-10s] %d%%\" % ('*'*i, 1*i))\n",
    "        sys.stdout.flush()\n",
    "        if i in scraped_page:\n",
    "            continue\n",
    "        page_url = url+str(i)\n",
    "        soup = get_soup(page_url, 'lxml')\n",
    "        get_data(soup)\n",
    "        scraped_page.append(i)\n",
    "    scraped_page = []\n",
    "        \n",
    "    scraped_categories.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quot</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love you as certain dark things are loved, s...</td>\n",
       "      <td>Pablo Neruda,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is an absolute human certainty that no one ...</td>\n",
       "      <td>John Joseph Powell,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I have learned anything in this long life o...</td>\n",
       "      <td>Kristin Hannah,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your handtouching mine.this is howgalaxiescoll...</td>\n",
       "      <td>Sanober Khan</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I choose to love you in silence…For in silence...</td>\n",
       "      <td>Rumi</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79613</th>\n",
       "      <td>The desire for human is good but do not forget...</td>\n",
       "      <td>Lailah Gifty Akita</td>\n",
       "      <td>Motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79614</th>\n",
       "      <td>Don't dim your light for someone who asks for ...</td>\n",
       "      <td>Govannie de Sadeleer</td>\n",
       "      <td>Motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79615</th>\n",
       "      <td>I alle forhold findes meddelagtighed, selv i b...</td>\n",
       "      <td>Peter Schellenbaum,</td>\n",
       "      <td>Motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79616</th>\n",
       "      <td>Package your gift and talent in such a way tha...</td>\n",
       "      <td>Dr. Lucas D. Shallua</td>\n",
       "      <td>Motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79617</th>\n",
       "      <td>Learn to diligently guard and protect your dre...</td>\n",
       "      <td>Dr. Lucas D. Shallua</td>\n",
       "      <td>Motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79618 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quot  \\\n",
       "0      I love you as certain dark things are loved, s...   \n",
       "1      It is an absolute human certainty that no one ...   \n",
       "2      If I have learned anything in this long life o...   \n",
       "3      your handtouching mine.this is howgalaxiescoll...   \n",
       "4      I choose to love you in silence…For in silence...   \n",
       "...                                                  ...   \n",
       "79613  The desire for human is good but do not forget...   \n",
       "79614  Don't dim your light for someone who asks for ...   \n",
       "79615  I alle forhold findes meddelagtighed, selv i b...   \n",
       "79616  Package your gift and talent in such a way tha...   \n",
       "79617  Learn to diligently guard and protect your dre...   \n",
       "\n",
       "                     author    category  \n",
       "0             Pablo Neruda,        Love  \n",
       "1       John Joseph Powell,        Love  \n",
       "2           Kristin Hannah,        Love  \n",
       "3              Sanober Khan        Love  \n",
       "4                      Rumi        Love  \n",
       "...                     ...         ...  \n",
       "79613    Lailah Gifty Akita  Motivation  \n",
       "79614  Govannie de Sadeleer  Motivation  \n",
       "79615   Peter Schellenbaum,  Motivation  \n",
       "79616  Dr. Lucas D. Shallua  Motivation  \n",
       "79617  Dr. Lucas D. Shallua  Motivation  \n",
       "\n",
       "[79618 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe('data.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output file.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
